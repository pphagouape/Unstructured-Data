{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 02: Análisis de Sentimiento de Títulos de Noticias Financieras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alumnos: *ingresar aquí el nombre de los alumnos a quienes corresponde esta entrega*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este taller implementarán un sistema de análisis de sentimiendo que tomando como input el texto escrito en los títulos de noticias financieras, detecta si las mismas son positivas, negativas o neutrales.\n",
    "\n",
    "El archivo *financial_headlines.csv* contiene los datos con los que deberán trabajar.\n",
    "\n",
    "La solución debe realizar los siguientes pasos y en el orden en que se presentan:\n",
    "\n",
    "1. Tokenizar todas las noticias tal cual lo hace la función *tokenize_all* presentada en clases (como ayuda este paso se entrega la función *load_financial_corpus*). Tengan presente que en este corpus a la variable de sentimiento la llamamos \"sentiment\", mientras que en el utilizado en clase la llamábamos \"rank\". De este modo, deberán modificar ligeramente la función *tokenize_all* para que funcione en este corpus (este comentario puede valer también para otras funciones vistas en clases que quieran reutilizar a lo largo de este taller).\n",
    "\n",
    "2. Dividir el corpus en dos conjuntos elegidos al azar. Un conjunto de entrenamiento (que debe contener el 70% de los datos) y un conjunto de testeo (que debe contener el restante 30% de los datos). Para esto se recomienda utilizar *train_test_split* de scikit-learn (vean: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "3. Generar matrices tipo document-term matrix para ambos conjuntos de datos. Para esto pueden (y se recomienda) dejar de lado en todos los conjuntos de datos los tokens menos frecuentes del conjunto de **entrenamiento** (IMPORTANTE: este conteo no debe hacerse sobre el conjunto testeo). Queda a su criterio definir qué es un token poco frecuente. Se pide que **no** realicen la transformación tf-idf.\n",
    "\n",
    "4. Entrenar un modelo de Random Forest usando como input el conjunto de entrenamiento. Recuerden que la clasificación (esto modelo debe predecir una de las tres clases: \"positive\", \"neutral\" y \"negative\"). Para este paso debe usar los valores por defecto de los hiperparámetros de random forest en scikit learn, salvo para el caso de *n_estimators* que debe ser igual a 400.\n",
    "\n",
    "5. Evaluar el sistema en el conjunto de testeo tal como lo hicimos en clases, salvo que en este caso, al ser un problema multiclase, se pide que no calculen el área bajo la curva ROC.\n",
    "\n",
    "Se pide que todo este sistema se encuentre implementado en esta notebook. Además del código presentado, se evaluará que la notebook esté bien explicada, sea prolija, y permita entender de manera simple qué es lo que están haciendo y por qué lo están haciendo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de ayuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_financial_corpus():\n",
    "    fin_data = pd.read_csv(\"financial_headlines.csv\", sep=\",\", encoding=\"latin-1\")\n",
    "\n",
    "    for _, row in fin_data.iterrows():\n",
    "        yield({\"id\": row[\"id\"], \"sentiment\": row[\"sentiment\"], \"raw_text\": row[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guia_oleo = load_financial_corpus()\n",
    "\n",
    "data = []\n",
    "for e in guia_oleo:\n",
    "    data.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí deberían ir completando todos los puntos que se piden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def tokenize(raw_text):\n",
    "    \"\"\" Tokenizes \"\"\"\n",
    "    raw_text = raw_text.replace(\"\\'\", \"'\")\n",
    "    raw_text = raw_text.replace(\"<br /><br />\", \"\\n\")\n",
    "    raw_text = raw_text.replace(\"/\", \" / \")\n",
    "    sentences = sent_tokenize(raw_text)\n",
    "    tokens = [e2 for e1 in sentences for e2 in word_tokenize(e1)]  # Nested list comprehension\n",
    "    tokens = [e.lower() for e in tokens if re.compile(\"[A-Za-z]\").search(e[0])]\n",
    "    \n",
    "    return(tokens)\n",
    "\n",
    "\n",
    "def text_to_bow(tokens):\n",
    "    return(Counter(tokens))\n",
    "\n",
    "\n",
    "def tokenize_all(corpus_iterator, size=None, print_every=100):\n",
    "    \"\"\" Processes all review \"\"\"\n",
    "    all_reviews = []\n",
    "    for i, r in tqdm(enumerate(corpus_iterator)):\n",
    "        tokens = tokenize(r[\"raw_text\"])\n",
    "        tokens_count = text_to_bow(tokens)\n",
    "        all_reviews.append({\"id\": r[\"id\"],\n",
    "                            \"sentiment\": r[\"sentiment\"],\n",
    "                            \"tokens\": tokens,\n",
    "                            \"tk_count\": tokens_count})\n",
    "        if size and (i+1) == size:\n",
    "            break\n",
    "    return(all_reviews)\n",
    "\n",
    "\n",
    "all_data = tokenize_all(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split([e for e in all_data], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_tokens(tokenized_data, min_freq):\n",
    "    \"\"\" Count words frequencies across the corpus\"\"\"\n",
    "\n",
    "    t_freqs = {}\n",
    "\n",
    "    for i, doc in enumerate(tokenized_data):\n",
    "        for t in doc[\"tk_count\"]:\n",
    "            t_freqs[t] = t_freqs.get(t, 0) + doc[\"tk_count\"][t]\n",
    "\n",
    "    frequent_tokens = set([e for e in t_freqs if t_freqs[e] >= min_freq])\n",
    "\n",
    "    return(frequent_tokens)\n",
    "\n",
    "\n",
    "def corpus_to_bow(tokenized_data, freq_tokens):\n",
    "    \"\"\" Shapes data as a pandas DataFrame \"\"\"\n",
    "\n",
    "    filt_tokens = []\n",
    "    for e in tokenized_data:\n",
    "        filt_tokens.append({k:e[\"tk_count\"][k] for k in e[\"tk_count\"] if k in freq_tokens})\n",
    "\n",
    "    ids = [e[\"id\"] for e in tokenized_data]\n",
    "    bag_of_words = pd.DataFrame(filt_tokens, index = ids)\n",
    "    bag_of_words = bag_of_words.reindex(columns=sorted(freq_tokens)).fillna(0)\n",
    "\n",
    "    ranks = pd.Series([e[\"sentiment\"] for e in tokenized_data], index = ids)\n",
    "\n",
    "    return(bag_of_words, ranks)\n",
    "\n",
    "freq_tokens = get_freq_tokens(train_data, 5)\n",
    "X_tr, y_tr = corpus_to_bow(train_data, freq_tokens)\n",
    "X_ts, y_ts = corpus_to_bow(test_data, freq_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 250, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_tr, y_tr)\n",
    "\n",
    "y_preds = rf.predict(X_ts)\n",
    "print(classification_report(y_ts, y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "28d32912ff785b10df1024f38ee4319211f818f7e33b0bebdd22a348463283c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
